{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c8f402-cc0c-436f-8898-06ecc316f51a",
   "metadata": {},
   "source": [
    "## **MetaBioPros 1.0**\n",
    "\n",
    "#### This notebook integrates the metagenomic bioprospecting analysis  1.0.  \n",
    "#### The analysis included are:  \n",
    "#### 0. Set env\n",
    "#### 1. Identification of BGCs\n",
    "#### 2. Taxonnomic annotation of BGCs\n",
    "#### 3. BGC sequences mapping onto referecne Gene Cluster Families (GCFs)\n",
    "#### 4. BGCs diversity estimates, functional prediction, and novelty assessment\n",
    "\n",
    "#### **Dependencies to run this notebook (outside the tools we provide):**  \n",
    "#### [aws cli](https://aws.amazon.com/cli/)  \n",
    "#### [bash and R kernels](https://evodify.com/python-r-bash-jupyter-notebook/)  \n",
    "#### [Docker](https://www.docker.com/)\n",
    "#### [RSQLite R library](https://cran.r-project.org/web/packages/RSQLite/index.html)\n",
    "#### [tidyverse R library](https://www.tidyverse.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc2398-db3e-4ec2-9b48-848bc6c832b8",
   "metadata": {},
   "source": [
    "**0. Set env**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1357053d-48e1-445e-a0de-e42f0da41828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WORKDIR=workdir\n",
      "env: REPO=/home/epereira/workspace/dev/new_atlantis/repos/bioprospecting\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython\n",
    "%set_env WORKDIR=workdir\n",
    "%set_env REPO=/home/epereira/workspace/dev/new_atlantis/repos/bioprospecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7003a2-c4e3-489f-b171-d1920dbd38df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p ${WORKDIR}/data/sola\n",
    "mkdir -p ${WORKDIR}/outputs/antismash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a9241-fdfe-4d2d-b5ee-c5537507ad63",
   "metadata": {
    "tags": []
   },
   "source": [
    " **1. Identification of BGCs**\n",
    " \n",
    "We will be using the [SOLA metagenomic dataset](https://www.nature.com/articles/s41396-018-0158-1), already assembled with [VEBA](https://github.com/jolespin/veba).\n",
    "Let’s first get the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b0f1c-7cb4-47b0-815d-fb8ac3723414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# aws s3 cp s3://newatlantis-case-studies/SOLA-samples/ ${WORKDIR}/data/sola --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a468a9-ac35-4c38-967b-6e68bb31bef8",
   "metadata": {},
   "source": [
    "This dataset contains the assembled scaffolds (\\*.fasta) and the mapping files (\\*.bam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e84e70-3389-49d3-9fad-9049dcb70132",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workdir/data/sola/ERR2604071/output:\n",
      "featurecounts.tsv.gz\n",
      "mapped.sorted.bam\n",
      "mapped.sorted.bam.bai\n",
      "scaffolds.fasta\n",
      "scaffolds.fasta.1.bt2\n",
      "scaffolds.fasta.2.bt2\n",
      "scaffolds.fasta.3.bt2\n",
      "scaffolds.fasta.4.bt2\n",
      "scaffolds.fasta.rev.1.bt2\n",
      "scaffolds.fasta.rev.2.bt2\n",
      "scaffolds.fasta.saf\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls ${WORKDIR}/data/sola/ERR*/output | head -12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcece54-3f7f-48fc-8bea-cd9d784a00b0",
   "metadata": {},
   "source": [
    "Now that we have the data, let's run [antisMASH](https://github.com/antismash/antismash) to identify the BGC sequences.  \n",
    "For this we will be using our wrap script [run_antismash](https://github.com/pereiramemo/bioprospecting/blob/main/run_scripts/run_antismash.sh), which runs a containerized version 6.0.0 of antiSMASH.  \n",
    "Note that there is version 7.0.0 available, but for compatibility purposes in downstream analysis, we'll use this version for now.\n",
    "Since we are using a wrap script to run a containerized version of antiSMASH, we have to use the fist two positional parameters as the input and output folders, respectively.  \n",
    "To see the help we run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04c291c2-f727-4198-9941-3cf538950c62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### antiSMASH 6.0.0 #############\n",
      "\n",
      "usage: antismash [--taxon {bacteria,fungi}] [--output-dir OUTPUT_DIR]\n",
      "                 [--output-basename OUTPUT_BASENAME] [--reuse-results PATH]\n",
      "                 [--limit LIMIT] [--minlength MINLENGTH] [--start START]\n",
      "                 [--end END] [--databases PATH] [--write-config-file PATH]\n",
      "                 [--without-fimo]\n",
      "                 [--executable-paths EXECUTABLE=PATH,EXECUTABLE2=PATH2,...]\n",
      "                 [--allow-long-headers] [-v] [-d] [--logfile PATH]\n",
      "                 [--list-plugins] [--check-prereqs]\n",
      "                 [--limit-to-record RECORD_ID] [-V] [--profiling]\n",
      "                 [--skip-sanitisation] [--skip-zip-file] [--minimal]\n",
      "                 [--enable-genefunctions] [--enable-tta]\n",
      "                 [--enable-lanthipeptides] [--enable-thiopeptides]\n",
      "                 [--enable-nrps-pks] [--enable-sactipeptides]\n",
      "                 [--enable-lassopeptides] [--enable-t2pks] [--enable-html]\n",
      "                 [--genefinding-tool {glimmerhmm,prodigal,prodigal-m,none,error}]\n",
      "                 [--genefinding-gff3 GFF3_FILE]\n",
      "                 [--hmmdetection-strictness {strict,relaxed,loose}]\n",
      "                 [--fullhmmer]\n",
      "                 [--fullhmmer-pfamdb-version FULLHMMER_PFAMDB_VERSION]\n",
      "                 [--cassis] [--clusterhmmer]\n",
      "                 [--clusterhmmer-pfamdb-version CLUSTERHMMER_PFAMDB_VERSION]\n",
      "                 [--sideload JSON] [--sideload-simple ACCESSION:START-END]\n",
      "                 [--tigrfam] [--smcog-trees] [--tta-threshold TTA_THRESHOLD]\n",
      "                 [--cb-general] [--cb-subclusters] [--cb-knownclusters]\n",
      "                 [--cb-nclusters count] [--cb-min-homology-scale LIMIT]\n",
      "                 [--asf] [--pfam2go] [--rre] [--rre-cutoff RRE_CUTOFF]\n",
      "                 [--rre-minlength RRE_MIN_LENGTH] [--cc-mibig]\n",
      "                 [--cc-custom-dbs FILE1,FILE2,...] [--html-title HTML_TITLE]\n",
      "                 [--html-description HTML_DESCRIPTION] [--html-start-compact]\n",
      "                 [-h] [--help-showall] [-c CPUS]\n",
      "                 [SEQUENCE [SEQUENCE ...]]\n",
      "\n",
      "\n",
      "arguments:\n",
      "  SEQUENCE  GenBank/EMBL/FASTA file(s) containing DNA.\n",
      "\n",
      "--------\n",
      "Options\n",
      "--------\n",
      "-h, --help              Show this help text.\n",
      "--help-showall          Show full lists of arguments on this help text.\n",
      "-c CPUS, --cpus CPUS    How many CPUs to use in parallel. (default: 48)\n",
      "\n",
      "Basic analysis options:\n",
      "\n",
      "  --taxon {bacteria,fungi}\n",
      "                        Taxonomic classification of input sequence. (default:\n",
      "                        bacteria)\n",
      "\n",
      "Additional analysis:\n",
      "\n",
      "  --fullhmmer           Run a whole-genome HMMer analysis.\n",
      "  --cassis              Motif based prediction of SM gene cluster regions.\n",
      "  --clusterhmmer        Run a cluster-limited HMMer analysis.\n",
      "  --tigrfam             Annotate clusters using TIGRFam profiles.\n",
      "  --smcog-trees         Generate phylogenetic trees of sec. met. cluster\n",
      "                        orthologous groups.\n",
      "  --tta-threshold TTA_THRESHOLD\n",
      "                        Lowest GC content to annotate TTA codons at (default:\n",
      "                        0.65).\n",
      "  --cb-general          Compare identified clusters against a database of\n",
      "                        antiSMASH-predicted clusters.\n",
      "  --cb-subclusters      Compare identified clusters against known subclusters\n",
      "                        responsible for synthesising precursors.\n",
      "  --cb-knownclusters    Compare identified clusters against known gene\n",
      "                        clusters from the MIBiG database.\n",
      "  --asf                 Run active site finder analysis.\n",
      "  --pfam2go             Run Pfam to Gene Ontology mapping module.\n",
      "  --rre                 Run RREFinder precision mode on all RiPP gene\n",
      "                        clusters.\n",
      "  --cc-mibig            Run a comparison against the MIBiG dataset\n",
      "\n",
      "Output options:\n",
      "\n",
      "  --output-dir OUTPUT_DIR\n",
      "                        Directory to write results to.\n",
      "  --output-basename OUTPUT_BASENAME\n",
      "                        Base filename to use for output files within the\n",
      "                        output directory.\n",
      "  --html-title HTML_TITLE\n",
      "                        Custom title for the HTML output page (default is\n",
      "                        input filename).\n",
      "  --html-description HTML_DESCRIPTION\n",
      "                        Custom description to add to the output.\n",
      "  --html-start-compact  Use compact view by default for overview page.\n",
      "\n",
      "Advanced options:\n",
      "\n",
      "  --reuse-results PATH  Use the previous results from the specified json\n",
      "                        datafile\n",
      "  --limit LIMIT         Only process the first <limit> records (default: -1).\n",
      "                        -1 to disable\n",
      "  --minlength MINLENGTH\n",
      "                        Only process sequences larger than <minlength>\n",
      "                        (default: 1000).\n",
      "  --start START         Start analysis at nucleotide specified.\n",
      "  --end END             End analysis at nucleotide specified\n",
      "  --databases PATH      Root directory of the databases (default:\n",
      "                        /usr/local/lib/python3.7/dist-\n",
      "                        packages/antismash/databases).\n",
      "  --write-config-file PATH\n",
      "                        Write a config file to the supplied path\n",
      "  --without-fimo        Run without FIMO (lowers accuracy of RiPP precursor\n",
      "                        predictions)\n",
      "  --executable-paths EXECUTABLE=PATH,EXECUTABLE2=PATH2,...\n",
      "                        A comma separated list of executable name->path pairs\n",
      "                        to override any on the system path.E.g.\n",
      "                        diamond=/alternate/path/to/diamond,hmmpfam2=hmm2pfam\n",
      "  --allow-long-headers  Prevents long headers from being renamed\n",
      "  --hmmdetection-strictness {strict,relaxed,loose}\n",
      "                        Defines which level of strictness to use for HMM-based\n",
      "                        cluster detection, (default: relaxed).\n",
      "  --sideload JSON       Sideload annotations from the JSON file in the given\n",
      "                        paths. Multiple files can be provided, separated by a\n",
      "                        comma.\n",
      "  --sideload-simple ACCESSION:START-END\n",
      "                        Sideload a single subregion in record ACCESSION from\n",
      "                        START to END. Positions are expected to be 0-indexed,\n",
      "                        with START inclusive and END exclusive.\n",
      "\n",
      "Debugging & Logging options:\n",
      "\n",
      "  -v, --verbose         Print verbose status information to stderr.\n",
      "  -d, --debug           Print debugging information to stderr.\n",
      "  --logfile PATH        Also write logging output to a file.\n",
      "  --list-plugins        List all available sec. met. detection modules.\n",
      "  --check-prereqs       Just check if all prerequisites are met.\n",
      "  --limit-to-record RECORD_ID\n",
      "                        Limit analysis to the record with ID record_id\n",
      "  -V, --version         Display the version number and exit.\n",
      "  --profiling           Generate a profiling report, disables multiprocess\n",
      "                        python.\n",
      "  --skip-sanitisation   Skip input record sanitisation. Use with care.\n",
      "  --skip-zip-file       Do not create a zip of the output\n",
      "\n",
      "Debugging options for cluster-specific analyses:\n",
      "\n",
      "  --minimal             Only run core detection modules, no analysis modules\n",
      "                        unless explicitly enabled\n",
      "  --enable-genefunctions\n",
      "                        Enable Gene function annotations (default: enabled,\n",
      "                        unless --minimal is specified)\n",
      "  --enable-tta          Enable TTA detection (default: enabled, unless\n",
      "                        --minimal is specified)\n",
      "  --enable-lanthipeptides\n",
      "                        Enable Lanthipeptides (default: enabled, unless\n",
      "                        --minimal is specified)\n",
      "  --enable-thiopeptides\n",
      "                        Enable Thiopeptides (default: enabled, unless\n",
      "                        --minimal is specified)\n",
      "  --enable-nrps-pks     Enable NRPS/PKS analysis (default: enabled, unless\n",
      "                        --minimal is specified)\n",
      "  --enable-sactipeptides\n",
      "                        Enable sactipeptide detection (default: enabled,\n",
      "                        unless --minimal is specified)\n",
      "  --enable-lassopeptides\n",
      "                        Enable lassopeptide precursor prediction (default:\n",
      "                        enabled, unless --minimal is specified)\n",
      "  --enable-t2pks        Enable type II PKS analysis (default: enabled, unless\n",
      "                        --minimal is specified)\n",
      "  --enable-html         Enable HTML output (default: enabled, unless --minimal\n",
      "                        is specified)\n",
      "\n",
      "Gene finding options (ignored when ORFs are annotated):\n",
      "\n",
      "  --genefinding-tool {glimmerhmm,prodigal,prodigal-m,none,error}\n",
      "                        Specify algorithm used for gene finding: GlimmerHMM,\n",
      "                        Prodigal, Prodigal Metagenomic/Anonymous mode, or\n",
      "                        none. The 'error' option will raise an error if\n",
      "                        genefinding is attempted. The 'none' option will not\n",
      "                        run genefinding. (default: error).\n",
      "  --genefinding-gff3 GFF3_FILE\n",
      "                        Specify GFF3 file to extract features from.\n",
      "\n",
      "Full HMMer options:\n",
      "\n",
      "  --fullhmmer-pfamdb-version FULLHMMER_PFAMDB_VERSION\n",
      "                        PFAM database version number (e.g. 27.0) (default:\n",
      "                        latest).\n",
      "\n",
      "Cluster HMMer options:\n",
      "\n",
      "  --clusterhmmer-pfamdb-version CLUSTERHMMER_PFAMDB_VERSION\n",
      "                        PFAM database version number (e.g. 27.0) (default:\n",
      "                        latest).\n",
      "\n",
      "TIGRFam options:\n",
      "\n",
      "NRPS/PKS options:\n",
      "\n",
      "ClusterBlast options:\n",
      "\n",
      "  --cb-nclusters count  Number of clusters from ClusterBlast to display,\n",
      "                        cannot be greater than 50. (default: 10)\n",
      "  --cb-min-homology-scale LIMIT\n",
      "                        A minimum scaling factor for the query BGC in\n",
      "                        ClusterBlast results. Valid range: 0.0 - 1.0. Warning:\n",
      "                        some homologous genes may no longer be visible!\n",
      "                        (default: 0.0)\n",
      "\n",
      "RREfinder options:\n",
      "\n",
      "  --rre-cutoff RRE_CUTOFF\n",
      "                        Bitscore cutoff for RRE pHMM detection (default:\n",
      "                        25.0).\n",
      "  --rre-minlength RRE_MIN_LENGTH\n",
      "                        Minimum amino acid length of RRE domains (default:\n",
      "                        50).\n",
      "\n",
      "ClusterCompare options:\n",
      "\n",
      "  --cc-custom-dbs FILE1,FILE2,...\n",
      "                        A comma separated list of database config files to run\n",
      "                        with\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\"${REPO}\"/run_scripts/run_antismash.sh . . --help-showall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d3bfdb-7eb1-40b4-920e-1be67935214b",
   "metadata": {},
   "source": [
    "Let's run antiSMASH on the SOLA dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eab970-dfaa-4d2f-a483-0b62306e8a88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERR2604071\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "SCAFOLDS=$(ls ${WORKDIR}/data/sola/ERR*/output/scaffolds.fasta | head -3)\n",
    "for SCAFOLD in ${SCAFOLDS}; do\n",
    "\n",
    "  SAMPLE_NAME=$(echo \"${SCAFOLD}\" | sed \"s/.*\\(ERR[0-9]\\+\\)\\/output.*/\\1/\")\n",
    "  OUTPUT_DIR=\"${WORKDIR}/outputs/antismash/${SAMPLE_NAME}\"\n",
    "  echo \"${SAMPLE_NAME}\"\n",
    "    \n",
    "  \"${REPO}\"/run_scripts/run_antismash.sh \"${SCAFOLD}\" \"${OUTPUT_DIR}\" \\\n",
    "  --cpus 40 \\\n",
    "  --genefinding-tool prodigal-m \\\n",
    "  --taxon bacteria \\\n",
    "  --allow-long-headers \\\n",
    "  --minlength 5000\n",
    "\n",
    "done    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335ff3ab-7de8-403a-a6ff-f7f193dcdf29",
   "metadata": {},
   "source": [
    "The annoated BGC sequences can be found in `${WORKDIR}/outputs/antismash/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5f46a84-8b51-4879-94da-c50e657f9fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERR2604071\n",
      "ERR2604073\n",
      "ERR2604074\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls ${WORKDIR}/outputs/antismash/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42888a2-1139-4204-aab5-5cbd4621af5c",
   "metadata": {},
   "source": [
    "Let's orgnize this data to run [BiG-SLICE](https://github.com/medema-group/bigslice): create the [dataset.tsv and taxonomy files](https://github.com/medema-group/bigslice/wiki/Input-folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33e2fc96-927e-4f41-aa35-82f57bd1be81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -d \"${WORKDIR}/outputs/antismash/\"ERR* | \\\n",
    "while read LINE; do\n",
    "\n",
    "  DATASET=$(basename $(ls -d ${LINE}))\n",
    "  PATH2DATASET=$(basename $(dirname ${LINE}))\"/\"\n",
    "  echo -e \"${DATASET}\\t./\\ttaxonomy/${DATASET}_taxonomy.tsv\\tdataset_${DATASET}\"\n",
    "\n",
    "done > \"${WORKDIR}/outputs/antismash/datasets.tsv\"\n",
    "\n",
    "# mkdir \"${WORKDIR}/outputs/antismash/taxonomy\"\n",
    "\n",
    "cut -f3 \"${WORKDIR}/outputs/antismash/datasets.tsv\" | \\\n",
    "while read LINE; do\n",
    "  DATASET=$(basename \"${LINE}\" _taxonomy.tsv)\n",
    "  echo -e \"${DATASET}/\\tBacteria\" > \"${WORKDIR}/outputs/antismash/${LINE}\"\n",
    "done\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b921001-f54f-4d55-8735-89b838d9eebe",
   "metadata": {
    "tags": []
   },
   "source": [
    "Download the [BiG-FAM database](https://bigfam.bioinformatics.nl/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7f84a1e-d112-46fc-8feb-63124f039bc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-09-04 22:21:03--  http://bioinformatics.nl/~kauts001/ltr/bigslice/paper_data/data/full_run_result.zip\n",
      "Resolving bioinformatics.nl (bioinformatics.nl)... 137.224.16.5\n",
      "Connecting to bioinformatics.nl (bioinformatics.nl)|137.224.16.5|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.bioinformatics.nl/~kauts001/ltr/bigslice/paper_data/data/full_run_result.zip [following]\n",
      "--2023-09-04 22:21:04--  https://www.bioinformatics.nl/~kauts001/ltr/bigslice/paper_data/data/full_run_result.zip\n",
      "Resolving www.bioinformatics.nl (www.bioinformatics.nl)... 137.224.16.5\n",
      "Connecting to www.bioinformatics.nl (www.bioinformatics.nl)|137.224.16.5|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18075963830 (17G) [application/zip]\n",
      "Saving to: ‘workdir/data/full_run_result.zip’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0%  137K 35h53m\n",
      "    50K .......... .......... .......... .......... ..........  0%  274K 26h54m\n",
      "   100K .......... .......... .......... .......... ..........  0% 12.7M 18h3m\n",
      "   150K .......... .......... .......... .......... ..........  0% 12.7M 13h38m\n",
      "   200K .......... .......... .......... .......... ..........  0%  282K 14h23m\n",
      "   250K .......... .......... .......... .......... ..........  0% 9.89M 12h4m\n",
      "   300K .......... .......... .......... .......... ..........  0% 12.2M 10h23m\n",
      "   350K .......... .......... .......... .......... ..........  0% 10.7M 9h9m\n",
      "   400K .......... .......... .......... .......... ..........  0%  297K 9h58m\n",
      "   450K .......... .......... .......... .......... ..........  0% 12.0M 9h0m\n",
      "   500K .......... .......... .......... .......... ..........  0% 11.9M 8h13m\n",
      "   550K .......... .......... .......... .......... ..........  0% 10.1M 7h35m\n",
      "   600K .......... .......... .......... .......... ..........  0% 11.7M 7h1m\n",
      "   650K .......... .......... .......... .......... ..........  0% 11.1M 6h33m\n",
      "   700K .......... .......... .......... .......... ..........  0% 10.7M 6h9m\n",
      "   750K .......... .......... .......... .......... ..........  0% 12.0M 5h47m\n",
      "   800K .......... .......... .......... .......... ..........  0% 7.18M 5h29m\n",
      "   850K .......... .......... .......... .......... ..........  0%  342K 5h58m\n",
      "   900K .......... .......... .......... .......... ..........  0% 11.9M 5h41m\n",
      "   950K .......... .......... .......... .......... ..........  0% 12.3M 5h25m\n",
      "  1000K .......... .......... .......... .......... ..........  0% 9.69M 5h11m\n",
      "  1050K .......... .......... .......... .......... ..........  0% 12.3M 4h58m\n",
      "  1100K .......... .......... .......... .......... ..........  0% 11.9M 4h46m\n",
      "  1150K .......... .......... .......... .......... ..........  0% 9.92M 4h35m\n",
      "  1200K .......... .......... .......... .......... ..........  0% 9.72M 4h25m\n",
      "  1250K .......... .......... .......... .......... ..........  0% 10.1M 4h16m\n",
      "  1300K .......... .......... .......... .......... ..........  0% 11.7M 4h8m\n",
      "  1350K .......... .......... .......... .......... ..........  0% 10.1M 4h0m\n",
      "  1400K .......... .......... .......... .......... ..........  0% 11.8M 3h52m\n",
      "  1450K .......... .......... .......... .......... ..........  0% 12.0M 3h45m\n",
      "  1500K .......... .......... .......... .......... ..........  0% 85.3K 5h29m\n",
      "  1550K .......... .......... .......... .......... ..........  0% 19.5K 13h10m\n",
      "  1600K .......... .......... .......... .......... ........"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# wget http://bioinformatics.nl/~kauts001/ltr/bigslice/paper_data/data/full_run_result.zip --directory-prefix  ${WORKDIR}/data/\n",
    "# unzip ${WORKDIR}/data/full_run_result.zip"
   ]
  },
  {
   "cell_type": "raw",
   "id": "671e865c-7374-478d-a859-dcfdfa0626e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "And now run [BiG-SLICE](https://github.com/medema-group/bigslice) using our containerized version. Let's first see the help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e8beb17-2584-40ed-8da1-adc06969b6f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: bigslice [-i <folder_path>] [--resume] [--complete] [--threshold T]\n",
      "                [--threshold_pct <N>] [--query <folder_path>]\n",
      "                [--query_name <name>] [--run_id <id>] [--n_ranks N_RANKS]\n",
      "                [-t <N>] [--hmmscan_chunk_size <N>] [--subpfam_chunk_size <N>]\n",
      "                [--extraction_chunk_size EXTRACTION_CHUNK_SIZE] [--scratch]\n",
      "                [--early_dumping] [-h] [--program_db_folder PROGRAM_DB_FOLDER]\n",
      "                [--version]\n",
      "                <output_folder_path>\n",
      "\n",
      "                            _________\n",
      " ___    _____|\\____|\\____|\\ \\____    \\\n",
      "|   \\  |       }     }     }  ___)_ _/__\n",
      "| >  | _--/--|/----|/----|/__/  __||  __|\n",
      "|   < | ||  __/ (  (| | \\___/  /__/|  _|\n",
      "| >  || || |_ | _)  ) |_ | |\\  \\__ | |__\n",
      "|____/|_| \\___/|___/|___||_| \\____||____| [ Version 1.1.0 ]\n",
      "\n",
      "Biosynthetic Gene clusters - Super Linear Clustering Engine\n",
      "(https://github.com/medema-group/bigslice)\n",
      "\n",
      "positional arguments:\n",
      "  <output_folder_path>  [Mandatory] the path to the (newly created or existing) output folder.\n",
      "\n",
      "[Mode 1] Clustering analysis:\n",
      "  Parse input datasets, then perform GCF models building (BIRCH clustering) and membership assignment according to the specified threshold (T)\n",
      "\n",
      "  -i <folder_path>, --input_folder <folder_path>\n",
      "                        [Mode-mandatory] Path to input folder containing 'datasets.tsv' file and dataset subfolders.\n",
      "  --resume              Continue the last clustering run (do not specifiy --input_folder in combination with this parameter).\n",
      "  --complete            When building GCF models, use only complete BGCs (antiSMASH > 4.2 BGCs annotated with 'on_contig_edge' = False).\n",
      "  --threshold T         Clustering threshold (T) used in GCF models building (BIRCH algorithm) and membership assignment [0-1.2]. Mutually exclusive with --threshold_pct, use '-1' to turn off this parameter (default: 0.4).\n",
      "  --threshold_pct <N>   Calculate clustering threshold (T) based on a random sampling of pairwise distances between the data, taking the N-th percentile value as the threshold. Mutually exclusive with --threshold, use '-1' to turn off this parameter (default: -1).\n",
      "\n",
      "[Mode 2] GCF queries:\n",
      "  Given existing GCF models from [Mode 1], perform features extraction and membership assignment from a set of BGC genbank files in the input folder\n",
      "\n",
      "  --query <folder_path>\n",
      "                        [Mode-mandatory] Path to input folder containing allcluster genbank files (needs to be either clusterXXX.gbk of antiSMASH4, regionXXX.gbk of antiSMASH5, or BGCXXXXXXX.gbk of MIBiG >= 2.0 files).\n",
      "  --query_name <name>   Give a unique name to the query run so that it will be easier to trace within the output visualization.\n",
      "\n",
      "[Mode 1+2]:\n",
      "  Parameters relevant for both the Clustering and Query mode\n",
      "\n",
      "  --run_id <id>         Rather than taking the latest run, perform query (or resume clustering) on the specific run id (you can check the list of run ids in the output visualization).\n",
      "  --n_ranks N_RANKS     Takes N-best GCF hits for each BGC's membership assignment procedure (default: 1).\n",
      "\n",
      "[Misc] Resource management:\n",
      "  CPU and RAM usage optimization parameters\n",
      "\n",
      "  -t <N>, --num_threads <N>\n",
      "                        The number of parallel jobs to run (default: 48).\n",
      "  --hmmscan_chunk_size <N>\n",
      "                        Split biosyn_pfam scanning into chunks of N BGCs (default: 100)\n",
      "  --subpfam_chunk_size <N>\n",
      "                        Split sub_pfam scanning into chunks of N BGCs (default: 100)\n",
      "  --extraction_chunk_size EXTRACTION_CHUNK_SIZE\n",
      "                        Split features extraction into chunks of N BGCs (default: 100)\n",
      "  --scratch             Don't load the Sqlite3 database into memory (lower RAM usage, but potentially slower).\n",
      "  --early_dumping       Dump the in-memory Sqlite3 db into a file after finishing every phase (will enable resume in case of crashes, but will increase overall runtime).\n",
      "\n",
      "[Misc] Other optional parameters:\n",
      "   \n",
      "\n",
      "  -h, --help            Show this help message.\n",
      "  --program_db_folder PROGRAM_DB_FOLDER\n",
      "                        Path to the HMM libraries (default: /usr/local/bin/bigslice-models).\n",
      "  --version             Show BiG-SLiCE version.\n",
      "\n",
      "_\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\"${REPO}\"/run_scripts/run_bigslice.sh query . . --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02605416-0207-4c3d-bfa9-797495deec86",
   "metadata": {
    "tags": []
   },
   "source": [
    "And now run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcefcf05-1e26-4fe3-a0d9-786edcf1506b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid 103's current affinity list: 0-47\n",
      "pid 103's new affinity list: 47\n",
      "pid 104's current affinity list: 0-47\n",
      "pid 104's new affinity list: 46\n",
      "pid 105's current affinity list: 0-47\n",
      "pid 105's new affinity list: 45\n",
      "pid 106's current affinity list: 0-47\n",
      "pid 106's new affinity list: 44\n",
      "pid 107's current affinity list: 0-47\n",
      "pid 107's new affinity list: 43\n",
      "pid 108's current affinity list: 0-47\n",
      "pid 108's new affinity list: 42\n",
      "pid 109's current affinity list: 0-47\n",
      "pid 109's new affinity list: 41\n",
      "pid 110's current affinity list: 0-47\n",
      "pid 110's new affinity list: 40\n",
      "pid 111's current affinity list: 0-47\n",
      "pid 111's new affinity list: 39\n",
      "pid 112's current affinity list: 0-47\n",
      "pid 112's new affinity list: 38\n",
      "pid 113's current affinity list: 0-47\n",
      "pid 113's new affinity list: 37\n",
      "pid 114's current affinity list: 0-47\n",
      "pid 114's new affinity list: 36\n",
      "pid 115's current affinity list: 0-47\n",
      "pid 115's new affinity list: 35\n",
      "pid 116's current affinity list: 0-47\n",
      "pid 116's new affinity list: 34\n",
      "pid 117's current affinity list: 0-47\n",
      "pid 117's new affinity list: 33\n",
      "pid 118's current affinity list: 0-47\n",
      "pid 118's new affinity list: 32\n",
      "pid 119's current affinity list: 0-47\n",
      "pid 119's new affinity list: 31\n",
      "pid 120's current affinity list: 0-47\n",
      "pid 120's new affinity list: 30\n",
      "pid 121's current affinity list: 0-47\n",
      "pid 121's new affinity list: 29\n",
      "pid 122's current affinity list: 0-47\n",
      "pid 122's new affinity list: 28\n",
      "pid 123's current affinity list: 0-47\n",
      "pid 123's new affinity list: 27\n",
      "pid 124's current affinity list: 0-47\n",
      "pid 124's new affinity list: 26\n",
      "pid 125's current affinity list: 0-47\n",
      "pid 125's new affinity list: 25\n",
      "pid 126's current affinity list: 0-47\n",
      "pid 126's new affinity list: 24\n",
      "pid 127's current affinity list: 0-47\n",
      "pid 127's new affinity list: 23\n",
      "pid 128's current affinity list: 0-47\n",
      "pid 128's new affinity list: 22\n",
      "pid 129's current affinity list: 0-47\n",
      "pid 129's new affinity list: 21\n",
      "pid 130's current affinity list: 0-47\n",
      "pid 130's new affinity list: 20\n",
      "pid 131's current affinity list: 0-47\n",
      "pid 131's new affinity list: 19\n",
      "pid 132's current affinity list: 0-47\n",
      "pid 132's new affinity list: 18\n",
      "pid 133's current affinity list: 0-47\n",
      "pid 133's new affinity list: 17\n",
      "pid 134's current affinity list: 0-47\n",
      "pid 134's new affinity list: 16\n",
      "pid 135's current affinity list: 0-47\n",
      "pid 135's new affinity list: 15\n",
      "pid 136's current affinity list: 0-47\n",
      "pid 136's new affinity list: 14\n",
      "pid 137's current affinity list: 0-47\n",
      "pid 137's new affinity list: 13\n",
      "pid 138's current affinity list: 0-47\n",
      "pid 138's new affinity list: 12\n",
      "pid 139's current affinity list: 0-47\n",
      "pid 139's new affinity list: 11\n",
      "pid 140's current affinity list: 0-47\n",
      "pid 140's new affinity list: 10\n",
      "pid 141's current affinity list: 0-47\n",
      "pid 141's new affinity list: 9\n",
      "pid 142's current affinity list: 0-47\n",
      "pid 142's new affinity list: 8\n",
      "pid 1's current affinity list: 0-47\n",
      "pid 1's new affinity list: 8-47\n",
      "Fetching run details...\n",
      "--run_id not specified, using Run#8...\n",
      "Parsing & inserting 37 GBKs...\n",
      "Inserted 37 BGCs!\n",
      "Preparing fasta files for hmmscans...\n",
      "Running hmmscans in parallel...\n",
      "Parsing hmmscans results...\n",
      "Preparing fasta files for subpfam_scans...\n",
      "Running subpfam_scans in parallel...\n",
      "Parsing subpfam_scans results...\n",
      "Extracting features...\n",
      "Assigning GCF membership...\n",
      "Query success! please check results via the output visualization (under 'Reports->View all reports')\n",
      "BiG-SLiCE run complete!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\"${REPO}\"/run_scripts/run_bigslice.sh query \\\n",
    "\"${WORKDIR}/outputs/antismash/\" \\\n",
    "\"${WORKDIR}/data/full_run_result\" \\\n",
    "--num_threads 40 \\\n",
    "--query_name SOLA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c221b687-8e6c-4a36-90c5-913ae14930c7",
   "metadata": {},
   "source": [
    "We can see the results in the folder `\"${WORKDIR}/data/full_run_result\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c91ef27f-8e39-4544-b833-65c06670f129",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "reports.db\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls \"${WORKDIR}/data/full_run_result/reports\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c997e1d-40d1-450e-ac7b-172a3757e2f4",
   "metadata": {},
   "source": [
    "The main result we obtain are the SQLite databases. Although we could access these utilizing the mini web application based on Flask library, we are going to import them into an R environment to have full control of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1660fc3c-7b9c-4982-a26c-6683ed7003d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0248f43a-6e4d-4c9e-95b0-aac2d4741cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "conn_reports_db <- dbConnect(RSQLite::SQLite(), \"workdir/data/full_run_result/reports/1/data.db\")\n",
    "conn_data_db <- dbConnect(RSQLite::SQLite(), \"workdir/data/full_run_result/result/data.db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0d819421-810b-4f9a-9754-eaebbda83105",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  name  seq\n",
      "1  bgc   37\n",
      "2  cds  449\n",
      "3  hsp 1109\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "dbListTables(conn_reports_db)\n",
    "dbReadTable(conn_reports_db, \"sqlite_sequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4086c611-cdff-4348-9961-87194dc4fd89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"bgc\"               \"bgc_class\"         \"bgc_features\"     \n",
      " [4] \"bgc_taxonomy\"      \"cds\"               \"chem_class\"       \n",
      " [7] \"chem_subclass\"     \"chem_subclass_map\" \"clustering\"       \n",
      "[10] \"dataset\"           \"enum_bgc_type\"     \"enum_run_status\"  \n",
      "[13] \"gcf\"               \"gcf_membership\"    \"gcf_models\"       \n",
      "[16] \"hmm\"               \"hmm_db\"            \"hsp\"              \n",
      "[19] \"hsp_alignment\"     \"hsp_subpfam\"       \"run\"              \n",
      "[22] \"run_bgc_status\"    \"run_log\"           \"schema\"           \n",
      "[25] \"sqlite_sequence\"   \"subpfam\"           \"taxon\"            \n",
      "[28] \"taxon_class\"      \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "dbListTables(conn_data_db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
